<P><A HREF="git-cc-96-06.book.html"><IMG SRC="fm2html-toc.gif">Table of Contents</A>
<A HREF="future-res-chapt.html"><IMG SRC="fm2html-previous.gif">Previous Chapter</A>
<!-- This file was created with the fm2html filter.
The filter is copyright Norwegian Telecom Research and
was programmed by Jon Stephenson von Tetzchner. -->

<TITLE>Introspective - CHAPTER XI</TITLE>

<H2><A NAME="REF34567"> CHAPTER XI  </A><BR>
<A NAME="HDR0">  RELATED RESEARCH</A></H2>

<DL>
<DL>
<DD><I>Here hills and vales, the woodland and the plain,
<BR>
<DD>Here earth and water seem to strive again,
<BR>
<DD>Not chaos-like together crush'd and bruis'd,
<BR>
<DD>But, as the world, harmoniously confus'd:
<BR>
<DD>Where order in variety we see, 
<BR>
<DD>And where, though all things differ, all agree.
<P>
<DD></I>_Alexander Pope (1713).
<P></DL>

</DL>


<P>Artificial intelligence certainly does not have a monopoly of interest concerning introspection and related topics such as learning and multistrategy reasoning.  Philosophers and observers of the human condition have been fascinated by the subjects for a very long time.  Around the turn of the 16th century in <I>De Trinitate</I>, Augustine asks "What then can be the purport of the injunction, Know thyself? I suppose it is that the mind should reflect upon itself."<A HREF="related-res2-chapt.html#FN1">(1)</A> More recently, Hofstadter (1979/1989) convincingly argues that the concept of reflection, or an object turning in upon itself (i.e., his concept of "Strange Loops"), is a common and powerful theme, in and outside of science.  Strange Loops can be found in mathematics (with the proofs of G&ouml;del), art (with the painting of Escher), and music (with the compositions of Bach).  But with few exceptions (e.g., Lyons, 1986, Pollock, 1989a), AI and cognitive psychology present the only mechanistic explanations for such phenomena and represent the only disciplines that address the issue in the context of learning. 

<P>The research that relates to the issues presented in this dissertation concerning multistrategy learning and introspection is prolific, and we have mentioned a number of the related research works already.  As a multistrategy learning theory, we have shown that the ideas behind Meta-AQUA fit into the strategy selection category of multistrategy models (see <A HREF="proc-chapt.html#REF39552">Section 5.4.1</A>).  In terms of failure-driven learning, we have characterized IML theory as a loose coupling between blame assignment and repair, in direct contrast to those theories that mandate a tight coupling (see <A HREF="learn-chapt.html#REF21830">Section 7.1</A>).  Because the preceding chapters have already connected much of the AI and psychology literatures to these and other individual issues, this chapter will not replicate the discussions.  Instead, the chapter examines the contrasting (and complementary) approaches to reasoning about the mental domain both literatures report, particularly in the context of learning.  It will review the history and current status of research into introspection of mental processes and reasoning about knowledge or beliefs.  Partitioned into two parts, this chapter will examine the broader issues that relate to introspection and introspective learning from an AI perspective (<A HREF="related-res2-chapt.html#REF13236">Section 11.1</A>) and from a psychological perspective (<A HREF="related-res2-chapt.html#REF60177">Section 11.2</A>).  The chapter concludes with a brief summary and discussion (<A HREF="related-res2-chapt.html#REF93044">Section 11.3</A>). 
<H3><A NAME="REF13236"> 11.1   Artificial Intelligence, Metareasoning, and Introspective Learning</A></H3>
<P>The AI community has long considered the possibility of providing machines with reflective faculties.  In recent years, a number of conferences and symposia have been organized to explore some of the issues that relate to this concern: the Workshop on Meta-level Architectures and Reflection held in Alghero, Italy, during October, 1986 (Maes &amp; Nardi, 1988); the International Workshop on Machine Learning, Meta-Reasoning and Logics held in Sesimbra, Portugal, during February, 1988 (Brazdil &amp; Konolige, 1990); the IMSA-92 Workshop on Reflection and Metalevel Architectures held in Tokyo, Japan, during November, 1992; the AAAI Spring Symposium on Representing Mental States held at Stanford University during March, 1993 (Horty and Shoham, 1993); and the AAAI Spring Symposium on Representing Mental States and Mechanisms held at Stanford during March, 1995 (Cox &amp; Freed, 1995).  In general, the loci of related research efforts has tended to focus the logic community on belief representation and introspective reasoning about such beliefs; the expert system community on metaknowledge and the control of rules; the planning community on search control and the choice of reasoning actions; and the case-based reasoning community on reasoning about reasoning failure and representations of process.  This section reviews the varieties of analysis pertaining to a computational theory of introspection and, more specifically, of introspective multistrategy learning. 

<P>From the very early days of AI, researchers have been concerned with the issues of machine self-knowledge and introspective capabilities.  Two pioneering researchers, Marvin Minsky and John McCarthy, pondered these issues and put them to paper in the mid-to-late 1950's.  Although first exchanged among colleagues, and then printed at conferences at the turn of the decade in preliminary form,<A HREF="related-res2-chapt.html#FN2">(2)</A> reprints of these papers were refined and gathered together in the seminal collection of early AI articles entitled <I>Semantic information processing</I> (Minsky, 1968b).  Minsky's (1968a) contention was that for a machine to adequately answer questions about the world, including questions about itself in the world, it would have to have a executable model of itself.  McCarthy (1968) asserted that for a machine to adequately behave intelligently it must declaratively represent its knowledge, including knowledge of itself.  These two positions have had far-reaching impact. 
<P>Minsky's proposal was procedural in nature while McCarthy's was declarative.  Minsky believed that an intelligent machine must have a computational model of the outside world from which a simulated execution could answer questions about actions in the world without actually performing any action.  He argued that if a machine uses models to answer questions about events in the world and the machine itself is in the world, then it must also use a recursive self-model or simulation to answer questions about itself, its own dispositions, and its own behavior in the world.  This was a very early prototype of a mental model that became a precursor to similar research in both problem solving and understanding (e.g., Bhatta, 1995; Bhatta &amp; Goel, 1992; Johnson-Laird, 1983;<A HREF="related-res2-chapt.html#FN3">(3)</A> deKleer &amp; Brown, 1983/1988; McNamara, Miller &amp; Bransford, 1991).  In the spirit of Minsky's original theme, some very novel work has also been performed to enable a machine to procedurally simulate itself (e.g., Stein and Barnden, 1995). 
<P>Although a closer examination of Minsky's propositions will be deferred until <A HREF="epilogue.html#REF39850">Section 13.2</A> of the epilogue, <A HREF="related-res2-chapt.html#REF82665">Section 11.1.1</A> explores McCarthy's proposals and their local impact on the logic community and their more global effect on the tone of research into a computational explanation of introspection.  <A HREF="related-res2-chapt.html#REF50914">Section 11.1.2</A> then looks at additional varieties of research in the expert-system and planning communities.  Finally, <A HREF="related-res2-chapt.html#REF58208">Section 11.1.3</A> relates some of the relevant research from the case-based reasoning and multistrategy learning communities to the research presented here. 
<H4><A NAME="REF82665"> 11.1.1  Logic and Belief Introspection </A></H4>

<P>As mentioned above, McCarthy (1968) not only establishes a manifesto for AI (i.e., knowledge representation is foundational, especially in declarative form), but suggests that machines can examine their own beliefs when such beliefs are explicitly represented.  This suggestion is developed in McCarthy and Hayes (1969) and made explicit in both Hayes (1979/1981) and McCarthy (1979).  A system requires such an introspective capability if it is to reason fully about the correctness of its knowledge.  This is especially useful because beliefs are subject to retraction in the face of new information (i.e., knowledge is nonmonotonic).  But beyond any technical details, McCarthy also wonders what it means for a machine to have a mental life.  McCarthy (1979) enumerates six reasons why attributing mental qualities to programs and machines is a useful effort.  Among them, he claims (as does Dennett's 1978 essay on the <I>intentional stance)</I> that humans can more quickly and more easily understand a program, its behavior, and its intended function by ascribing beliefs and goals to the machine than by analyzing and explaining it in the language of program code and computer states.  But most interestingly, McCarthy takes the business of understanding and simulating a machine's mental life beyond a mere practical metaphor.  He questions what it means for a machine to have consciousness and to introspect about its mental world.  Furthermore, he realizes that "introspection is essential for human level intelligence and not a mere epiphenomenon." (McCarthy, 1995, p. 89) Thus, he is keenly interested in the relation between machine and human introspection. 
<P>McCarthy (1979) defines introspection as a machine having a belief about its own mental states rather than about propositions concerning the world.  This position has focussed the logic community, especially researchers such as Konolige (1985, 1988) and Moore (1995), on reasoning about knowledge, belief, and internal states, rather than reasoning about process and computation.  McCarthy (1993) further formalizes the idea of introspection by introducing context as a first-class object that can be reasoned about.  By encapsulating mental situations in formalized contexts, the reasoner can view the mental state as providing an outer context.  Reasoning about one's own thoughts then involves transcending the outer context (McCarthy, 1993).  Unlike our work, however, the realization of such an introspective mechanism has not been implemented in a computational system.  Furthermore, McCarthy (1995) notes that even though reason maintenance systems (e.g., Doyle, 1979) record justifications for their beliefs and can retract beliefs in response to new information, they do not have the capability of inspecting the justification structures or making specific assertions about them, nor do they have the power to derive explanations from such structures.  

<P>Although some in the logic community have generalized the logical approach to cover many mental attitudes (e.g., Ballim, 1993),<A HREF="related-res2-chapt.html#FN4">(4)</A> the preponderance of research has been limited to deductive reasoning concerning belief and uncertainty.  This same research bias is evident in the philosophical literature on mental representations of internal states and the theory of mind (e.g., Stich &amp; Warfield, 1994; but see Lyons, 1986, for a prominent exception).  Because of the philosophical roots of logic, much of the research by logic-oriented researchers tend to focus on <I>justified true belief</I> and how one can <I>know</I> a proposition is true (classical epistemology).  The focus is on idealized thought, rather than on developing descriptive theories of actual human error-prone thought.  Logical theories are prescriptive in the sense that they outline how people ought to think, not how they do think.  This research focus has forced the logicians into grappling with how reasoners can maintain a consistent and complete set of propositions and how reasoners can deduce only correct propositions from such a set.  The advantage of such an orientation is that a system can have confidence about inferences and propositions in this set; but, the disadvantage is that if the set becomes inconsistent, then from one inconsistency a system can prove false assertions.  Despite the fact that McCarthy and others have imbued research on introspection with a sense of legitimacy, the most damaging general criticism of the logic approach is that the metaphor of "thought as a logical proof" is limited when applied to human thinking and learning.  Much of the reasoning process is simply not deductive (McDermott, 1987/1992).  But with respect to our IML theory, a critical omission is that learning is never addressed by their intellectual dialogues.  
<H4><A NAME="REF50914"> 11.1.2  Knowledge-Based Systems, Quasi-Introspection, and Related Theories </A></H4>
<P>The expert system community has also invested much effort into the formalization of metareasoning and metaknowledge.  It was recognized in the late 1970's that differences exist between domain knowledge in the form of expert rules, and declarative control knowledge in the form of meta-rules (Davis, 1979, 1980; see also Clancey &amp; Bock, 1985).  Metarules encode knowledge about how rules should be executed, whereas ordinary rules encode domain-specific knowledge.  Barr (1977, 1979) noted, as we do here, the parallel relation between higher-order knowledge and reasoning by knowledge-based systems and human metacognition (see also Lenat, Davis, Doyle, Genesereth, Goldstein, &amp; Schrobe, 1983).  Especially when trying to automate the transfer of domain knowledge from human expert to machine expert, these and other researchers have attempted to give programs abstract knowledge of human reasoning and inference procedures, so that programs can understand human experts (see for example, Clancey, 1987).  Additionally, when expert systems explain a conclusion by providing to the user a list of rules through which the system chained to generate the conclusion, the system is said to introspect about its own reasoning.  This view appears, however, to be an over-simplified example of both introspection and explanation. 

<P>Davis and Buchanan (1977) claim that four types of meta-level knowledge exist: knowledge about object representations (encoded in schemata), knowledge about function representation (encoded in function templates), knowledge about inference rules (encoded in rule models), and knowledge about reasoning strategies (encoded in metarules).  But much of this information is less akin to introspective knowledge than it is to ordinary abstract knowledge.  For example, to claim that default inheritance and learning are inherently introspective processes (Maes, 1987b) or that extrapolating from past experience is reflective thinking (Smith, 1982/1985) is perhaps stretching the definitions of introspection and reflection, respectively. 
<P>As another example, Genesereth (1983; also Maes, 1988) considers the meta-level to be that which decides about the base-level (or actions in the world) and explicitly includes planning as a meta-level reasoning process.  This unfortunately conflates metareasoning with reasoning because the system is not reasoning about the reasoning process itself.<A HREF="related-res2-chapt.html#FN5">(5)</A> Instead, three levels exist: object, reasoning, and meta-reasoning levels.  For example, John Self (1992) argues that a metacognitive component is crucial in student modeling for intelligent learning environments and proposes three levels.  The base level, B, contains both rules and propositions specific to the particular tutoring domain.  The reasoning level, R, contains descriptions of the processes that operate on and change the B level.  Finally, the meta level, M, contains descriptions of those processes that monitor the progress of the reasoning level processes and reason about the outcomes of the R level.  Processes in the R level produce changes in the B level, and processes in the M level produce changes in the R level.  Stefik (1981) also emphasizes this three-level configuration.

<P>Another popular research issue is to develop systems that can reason about LISP functions and the actual code that represents a program's control (Batali, 1983; Davis &amp; Buchanan, 1977; Maes, 1987a, 1988; Smith, 1982/1985).  However, this form of "introspection" is too low-level.  Programs need to reason about the functioning at the level of cognitive process, not at the level of program execution.<A HREF="related-res2-chapt.html#FN6">(6)</A> Some in the AI community are recognizing some of the more subtle differences between the different families of metareasoning.  For example, Clancey (1992) notes that many of the metarules employed by systems such as TEIRESIAS (Davis, 1979), although dealing with control, are nonetheless domain specific.  He claims that strategic knowledge is inherently procedural whereas domain specific knowledge is rule-based.  Moreover, unlike his previous work (e.g., Clancey, 1987), he currently eschews modeling the mental process that the expert uses when reasoning about the domain, and instead emphasizes modeling the domain that the expert knows.  This change of focus, however, seems to be as much a concession to the difficulty of representing introspective knowledge as it is a necessity dictated by representation itself. 
<P>Although many in the artificial intelligence community have recognized the necessity of reasoning about one's own beliefs, few have both modeled and represented the processes that <I>generates</I> beliefs, and made them available to the reasoner itself.  In this category of reflective systems, a distinction exists between those systems that reason forward to decide what action to perform or what computation to execute, and those that reason backward to explain a failure or learn.  This is related to the distinction made in the psychological literature between forward strategic control and backward metacognitive monitoring (see the discussion of Nelson &amp; Narens, 1990/1992 in <A HREF="related-res2-chapt.html#REF62733">Section 11.2.3</A>).  In the former category, systems attempt to choose a reasoning action based on some knowledge of the mental actions at the disposal of the system.  Doyle (1980), as well as Russell and Wefald (1991a, 1991b; Tash &amp; Russell, 1994), use probabilistic estimations to decide which computation has the most likely utility.  Etzioni (1991) uses decision-analytic methods to weigh the trade-off between deliberation cost, execution cost and goal value when choosing a goal toward which to direct attention and when deciding which action to take in service of a chosen goal.  The latter category of systems (backward metacognitive monitoring) is examined in the next section. 
<P>By some measures, few people are working on introspection, but in another sense used by some in the AI community, everyone in AI must be working on introspection and metareasoning.  Most intelligent programs deliberate to some extent about the types of actions that are optimal given their goals.  For example, Soar (Newell, 1990; Laird et al., 1986; Rosenbloom et al., 1993), Theo (Mitchell, et al., 1991), and PRODIGY (Carbonell et al., 1991; Minton et al., 1987) are all programs that make deliberate decisions as to the best action available in their domains.  Moreover, if metaknowledge is taken to be any abstract knowledge (e.g., default knowledge), and metareasoning is any of the higher cognitive functions (e.g., planning), then ironically CBR is one of the few non-introspective reasoning paradigms remaining because it reasons from concrete experience and episodes (tokens, rather than abstract types).  We agree with Maes' (1987b) assessment that an introspective system is one whose domain is itself.  But in the research presented here, we further define an introspective reasoner to be a system that <I>reasons</I> specifically about itself (its knowledge, beliefs, and its reasoning process), not those that simply <I>use</I> such knowledge.  As demonstrated in <A HREF="eval-chapt.html#REF43294">Chapter IX</A>, this is crucial for effective learning. 
<H4><A NAME="REF58208"> 11.1.3  Relation of AI Research to IML Theory</A></H4>

<P>Although many systems use higher order knowledge and processes in intelligent tasks, the theory presented here is one of only a few that use introspection to support learning in response to failure.  That is, the Meta-AQUA system keeps a trace of its reasoning in order to reason backwards towards the failure causes and to formulate a plan to change its knowledge.  As reiterated in this text, several fundamental problems must be addressed to create such learning plans or strategies.  These problems are (1) determining the cause of a reasoning failure (blame assignment), (2) deciding what to learn (learning goal formulation), and (3) selecting and ordering the best learning methods to pursue its learning goals (strategy construction).  A learning system that determines why reasoning fails, formulates its own learning goals, and constructs a learning strategy needs the ability to introspect about its own reasoning processes and knowledge.  In support of such an assertion, Collins et al.  (1993) argue that to plan effectively a system must have an explicit model of its of planning and execution processes.<A HREF="related-res2-chapt.html#FN7">(7)</A> In this dissertation, we have argued more generally that to learn, a system must have an explicit model of its performance task. 
<P>In general, our orientation is similar to the approaches based on reasoning traces (e.g., Carbonell, 1986; Minton, 1988; Sussman, 1975) or justification structures (e.g., Birnbaum, Collins, Freed, &amp; Krulwich, 1990; deKleer, Doyle, Steele, &amp; Sussman, 1977; Doyle, 1979) to represent problem-solving performance and to other approaches that use characterizations of reasoning failures for blame assignment and multistrategy learning (e.g., Kass, 1990; Mooney &amp; Ourston, 1991; Owens, 1990a; Park &amp; Wilkins, 1990; Redmond, 1992; Stroulia &amp; Goel, 1992).  Reasoning trace information has primarily been used for blame assignment during planning (e.g., Collins et al., 1993; Birnbaum et al., 1990; Veloso &amp; Carbonell, 1994) and for speedup learning (e.g., Mitchell, Keller, &amp; Kedar-Cabelli, 1986).  A major difference between our approach and these approaches is our use of explicit representational structures (Introspective Meta-XPs) to represent classes of learning situations along with the types of learning needed in those situations. 

<P>Other types of knowledge may also be important in multistrategy or introspective learning systems.  For example, Pazzani's (1991) OCCAM system has generalized knowledge about physical causality that is used to guide multistrategy learning.  In contrast, we propose specific knowledge about classes of learning situations that can be used to guide learning strategy selection and construction.  The IULIAN system of Oehlmann, Edwards and Sleeman (1995) maintains metacognitive knowledge in declarative introspection plans.  The RFermi system (Kennedy, 1995) maintains goal and memory search information to represent knowledge about its memory performance.  This information allows it to introspectively determine improvements in its search behavior.  Freed's RAPTER system (Cox &amp; Freed, 1994; Freed &amp; Collins, 1994) uses three types of self-knowledge when learning.  Records of variable bindings maintain an implicit trace of system performance, justification structures provide the knowledge of the kinds of cognitive states and events needed to explain the system's behavior, and transformation rules (Collins, 1987; Hammond, 1989) describe how the mostly implementation-independent knowledge in justification structures corresponds to a particular agent's implementation.  In the Meta-AQUA system, however, TMXPs maintain reasoning traces explicitly, and most implementation-dependent knowledge is avoided. 
<P>Our approach to using an analysis of reasoning failures to determine what needs to be learned is similar to Mooney and Ourston's (1991) EITHER system, Park and Wilkins' (1990) MINERVA program, the CASTLE system of Krulwich (1993; Collins et al., 1993), Fox's (1995; Fox and Leake, 1995a, 1995b) ROBBIE path planning system, and Stroulia's (1994; Stroulia &amp; Goel, 1995) Autognostic system, but with some important differences.  We have focused on the use of meta-models for explicit representation of domain knowledge and of reasoning processes in an integrated, multistrategy reasoning and learning system.  Unlike both Mooney and Ourston and Park and Wilkins, we have not assumed a single reasoning paradigm (logic-based deduction and rule-based expert systems, respectively) in terms of which failure situations and learning strategies are characterized.  Rather, it is the architecture that provides a basis for a higher-level characterization, which in turn could be implemented in different ways depending on the reasoning paradigm.  In fact, Meta-AQUA uses multiple reasoning methods, primarily case-based reasoning.
<P>Birnbaum et al. (1990) focus on the process of blame assignment by backing up through justification structures, but do not emphasize the declarative representation of failure types.  They explicitly model, however, the planner.  They also explicitly model and reason about the intentions of a planner in order to find and repair the faults that underlie a planning failure (see Freed et al., 1992).  Though much is shared between CASTLE and Meta-AQUA in terms of blame assignment (and to a great extent CASTLE is also concerned with deciding what to learn; see Krulwich, 1991), CASTLE does not use failure characterizations to formulate explicit learning goals nor does it construct a learning strategy in a deliberate manner within a multistrategy framework.  The only other system to introspectively deliberate about the choice of a learning method is the ISM system of Cheng (1995).  ISM optimizes learning behavior dynamically and under reasoning failure or success, but the system chooses the best <I>single</I> learning algorithm, rather than composing a strategy from multiple algorithms.  ISM does not therefore have to consider algorithm interactions. 

<P>Finally, our work focuses on reasoning failures, and not only on performance failures (in both the Collins et al. and Owens' cases, planning failures).  Stroulia's approach focuses on a design stance characterization of the reasoner as a device, whereas our approach, as with the approach of Collins, Birnbaum, and their colleagues, takes a more intentional stance toward the reasoner.<A HREF="related-res2-chapt.html#FN8">(8)</A> The analysis of Stroulia (1994), characterizing the ways in which such a device could fail, yields a taxonomy of failure types similar to ours.  However, like the previous studies, she too does not use declarative characterizations of reasoning failures to formulate explicit learning goals.  Furthermore, the CASTLE, Autognostic, ROBBIE, and RAPTER systems are all model-based in their introspective methods, whereas Meta-AQUA is XP-based (case-based).  Finally, none of these systems create an explicit plan to learn in the space of changes to the BK.  Despite these differences, we emphasize that the approaches enumerated in this section have much in common with IML theory.  The following section demonstrates that commonalities also exist within much of the psychological community's research that investigate how persons perceive their own minds, memories and knowledge. 
<H3><A NAME="REF60177"> 11.2   Psychology, Metacognition, and Human Learning </A></H3>
<P>The literature on metacognition (cognition about cognition where the self is a referent) and metamemory (memory and knowledge about ones own memory system and retrieval ability) provides a wide array of influences and support that bear on the research presented here.  Our model of introspective learning makes several claims about the nature of learning, reasoning, and introspection that are supported by research in psychology on metacognition.  This support includes the emphasis on cognitive self-monitoring, the importance of explicit representation, the emphasis on understanding one's own memory system, and the data demonstrating a person's ability to assess the veracity of their own responses and learning. 
<H4><A NAME="REF85421"> 11.2.1  Cognition and Metacognition</A></H4>

<P>Since Flavell's (1971) coining of the term metacognition, and especially since the seminal work of Flavell and Wellman (1977), many have investigated the phenomenon surrounding cognition about cognition.<A HREF="related-res2-chapt.html#FN9">(9)</A> Of all research on the modern-day concept of metacognition, the child development literature has the longest history (see, for example, Yussen, 1985).  Moreover, developmental psychology has reported the most conclusive evidence for the importance of metacognitive strategies and monitoring (see Schneider, 1985; Wellman, 1983).  Researcher interested in learning disabilities have studied the metacognitive components of such pathologies.  For example, <I>Part II: Macrolevel Cognitive Aspects of Learning Disabilities</I> (Ceci, 1987) contains a number of papers relevant to this type of investigation.  Research examining the relationship between metacognitive skills and educational instruction have made significant progress.  For example, Forrest-Pressley, MacKinnon, and Waller (1985) and Garner (1987) report successful instruction procedures related to both problem solving and reading comprehension (see also Ram &amp; Leake, 1995, for a related discussion).  Most of these works concentrate on applications relevant to teaching in general school environments, although some address specific instruction of the learning disabled.  Finally, the social psychology and philosophical communities have all taken considerable interest in individuals' beliefs about their own beliefs and beliefs about others' beliefs (e.g., Antaki &amp; Lewis, 1986; Pollock, 1989a, 1989b).<A HREF="related-res2-chapt.html#FN10">(10)</A>
<P>Wellman (1983, 1985) views human metacognition not as a unitary phenomenon, but rather as a multifaceted theory of mind.  Metacognition involves several separate but related cognitive processes and knowledge structures that share as a common theme the self as referent.  Such a theory of mind emerges from of an awareness of the differences between internal and external worlds, that is, from the perception that there exist both mental states and events that are quite discriminable from external states and events.  This theory encompasses a number of knowledge classes considered by Wellman to be psychological variables: <I>person variables</I> that deal with the individual and others (for example, cognitive psychologists can recall many facts about cognition, whereas most people cannot), <I>task variables</I>, which concern the type of mental activity (for example, it is more difficult to remember nonsense words than familiar words), and <I>strategy variables</I> that relate to alternative approaches to a mental task (e.g., to remember a list it helps to rehearse).  Finally, Wellman's theory includes a self-monitoring component, whereby people evaluate their levels of comprehension and mental performance with respect to the theory and the norms the theory predicts.
<H4><A NAME="REF68376"> 11.2.2  Problem Solving and Metacognition</A></H4>
<P>Problem solving is one area where a natural fit exists to studies of higher cognitive processing, such as executive control and monitoring, and where much leverage for metacognitive knowledge could be gained by humans.  However, few studies have examined this phenomena explicitly.  Some are reported here. 

<P>D&ouml;rner (1979) reports one of the earliest experiments on the effects of cognitive monitoring on problem solving.  The experimental design categorizes subjects into one of two conditions according to how they perform protocols after problem solving.  In the introspective condition, subjects reflect out loud about their own reasoning during problem solving, whereas subjects in the control group discuss their solution to the problem in terms of the hypotheses they developed.  The experiment itself involves a complicated machine with three lights.  Each light can be turned on in four different colors.  There are eight push-buttons on the machine with which subjects control the lights and their colorations.  The subjects solve ten problems during the experimental trials.  Problems consist of an initial state in which the lights of the machine begin operation and a goal state consisting of a different light configuration.  D&ouml;rner reports that the experimental group performs significantly better than the control group after the third trial.  Moreover, D&ouml;rner claims that introspective subjects exhibited improved performance during transfer tasks of subsequent experiments, although the details of many of the experiments are lacking.
<P>Derry (1989) offers a comprehensive model of reflective problem solving for mathematical word problems inspired by John Anderson's ACT* (Anderson, 1983) and PUPS (Anderson &amp; Thompson, 1989) theories of general cognition.  Based on such a theory, Derry and her colleagues have developed an instructional system to teach word problems to military servicemen.  Prior to the development of this application, Derry performed the following experiment on groups of college students and military personnel.  Given an assumption that general problem solving behaviors, such as reasoning from the goal backwards to the solution and means ends analysis, form the bases for human problem solving, the experimenter gathered subject protocols during solution of mathematical word problems.  The protocols were classified into 27 categories falling into four basic phases of problem solving: clarifying a problem, developing a strategy, executing a strategy, and monitoring/checking performance.  The surprising result was that neither group performed problem solving in a linear fashion, and that most protocols were classified into clarifying and execution phases.  The strategy-development and monitoring/checking phases lacked significant protocols.
<P>Delclos and Harrington (1991) report that both subject conditions with general problem-solving skill training and those with problem-solving coupled with metacognitive skill training demonstrate equal performance on a problem solving task.  With greater task complexity, though, subjects with the problem-solving/metacognitive training perform better than either a control group or the problem solving training alone group.  Also, Swanson (1990) claims to have established the independence of general problem aptitude from metacognitive ability.  Subjects with relatively low aptitude, but high metacognitive ability, often use metacognitive skills to compensate for low ability so that their performance is equivalent to high aptitude subjects.

<P>Kluwe (1987) examines the effect of problem-solving task demands on regulatory behavior in subjects aged four through seven.  By varying reversibility and irreversibility conditions in multiple puzzle-solving tasks (i.e., the first condition allows pieces of the puzzle to be placed and then moved to alternative locations, whereas the second condition allows no movement once a piece is placed), Kluwe sought to measure the differences in problem solving strategies.  Results show that although some activities change regardless of age (for instance, all subjects increase the duration and amount of problem-solving operations under the irreversibility condition), other activities (such as grouping the pieces) are present in only the older subjects.
<P>Finally, Davidson, Deuser, and Sternberg (1994) present results from a series of studies that show the use of metacognitive abilities correlate with standard measures of intelligence.  In their experiments on insight problem-solving they report that, although higher IQ subjects are slower rather than faster on analyzing the problems and applying their insights (not surprising if more processing is being performed), their performance is higher.  They argue that the difference in performance is due to effective use of metacognitive processes of problem identification, representation, planning how to proceed, and solution evaluation, rather than problem solving abilities <I>per se</I>. 
<P>This section has illustrated some of the findings that describe how humans introspect about their cognitive performance (processes) when solving problems and how this ability can lead to improved performance.  Although the findings are mixed, and no researcher claims that humans are inwardly omniscient, the results support the relevance of IML theory for modeling intelligence and learning.  The next section examines the research into people's ability to understand their own memory systems (content). 
<H4><A NAME="REF62733"> 11.2.3  Metamemory</A></H4>
<P>A large bulk of the research into metacognition pertains predominantly to metamemory knowledge and monitoring of memory performance.  Kausler (1991) groups this research into three broad categories: off-line memory self-evaluation, on-line memory self-evaluation, and memory performance monitoring.  <I>Off-line evaluation</I> of memory concerns a subject's perception of the efficiency and general operation of the subject's memory functions.  This is often determined by the use of a questionnaire and then correlated with subsequent memory performance in experiments.  For a thorough review of this line of research, see Hultsch, Hertzog, Dixon, &amp; Davidson (1988). 
<P><I>On-line evaluation</I> reports a subject's judgement of their performance in a particular memory task.  Both feelings-of-knowing (FOK, i.e, judgements of being able to recognize items that are not recalled) and judgements-of-learning (JOL, i.e., judgements while training as to the likelihood of future recall) responses are examples of on-line evaluations.  For instance, Lovelace and Marsh (1985) demonstrate that during study, older subjects' judgements of their future ability to perform a paired-associate matching task is less accurate than younger subjects' estimates. 

<P>Finally, <I>memory performance monitoring</I> is the ability of a subject to associate certain memory strategies with various memory demands or tasks.  For example, experiments may test subjects ability to choose appropriate strategies for memory problems by giving the subject unlimited time to study test words, then measure the amount of time spent in rehearsal.  The length of rehearsal time is an index into the subject's knowledge of the behavior necessary to learn the stimulus.  Other experiments in this category (e.g., Brigham &amp; Pressley, 1988) measure this ability more directly.  Brigham and Pressley report that after practice and feedback, older subjects are less able to determine that a keyword mnemonic strategy is superior to a strategy that generates semantic contexts for recalling word lists than are younger subjects, and therefore do not develop a preference for the better strategy when studying.
<P>Lovelace (1990) subdivides the on-line memory self-evaluation research category into two additional groups: Pre-performance estimates of memory and memory monitoring (not to be confused with what Kausler calls memory performance monitoring).  The <I>pre-performance estimates</I> paradigm requires subjects to predict subsequent memory performance, and then compares estimates to actual behavior.  <I>Memory monitoring</I>, on the other hand, concern a subject's ability to evaluate and act upon current memory-states during task performance.  These abilities include other subdivisions according to Lovelace: FOK or tip-of-the-tongue phenomena, correctness of response (postdictions), and reality monitoring.<A HREF="related-res2-chapt.html#FN11">(11)</A> FOK judgements correspond to subjects' estimates about their future recognition of currently unrecalled memory items; whereas postdictions concern a subject's belief in the veracity of their responses immediately after they have been given.  Reality monitoring is the differentiation between acts performed in the world and those performed in the head (in plans, dreams, imagination, etc.). 

<P>Nelson and Narens (1990/1992) present a general information-processing framework for integrating and better understanding metacognition and metamemory.  Behind the framework lie three basic principles: 1. Cognitive processes are split into an object-level and a meta-level; 2. The meta-level contains a dynamic model of the object-level; and 3. A flow of information from the object-level to the meta-level is considered monitoring, whereas information flowing from the meta-level to the object-level is considered control.  Although the framework is similar to Self's model (see <A HREF="related-res2-chapt.html#REF50914">Section 11.1.2</A> <A HREF="related-res2-chapt.html#REF0">page 268</A>), it differs in that it directly integrates much of the research surveyed in sections <A HREF="related-res2-chapt.html#REF68376">11.2.2</A> and <A HREF="related-res2-chapt.html#REF62733">11.2.3</A>.  The theory addresses knowledge acquisition, retention, and retrieval in both monitoring and control directions of information flow.  Monitoring processes include ease-of-learning judgements, JOLs, FOKs and confidence in retrieved answers.  Control processes include selection of the kind of processes, allocation of study time, termination of study, selection of memory search strategy, and termination of search.  Both acquisition and retrieval of memory items have computationally explicit decompositions in their paper.  Although the framework is directed at memory related performance rather than inference-based problem-solving, the distinctions between monitoring and control and the information processing perspective is highly compatible with the views presented in IML theory.  We provide a monitoring capacity for detecting failure and a control capability for guiding learning. 
<H4><A NAME="REF22489"> 11.2.4  Relation of Psychological Research to IML Theory</A></H4>
<P>The preceding subsections examined some of the related research in the metacognition and metamemory communities.  This section attempts to reorganize these results with respect to the theory of learning presented in this dissertation.  Research regarding metacognition and metamemory processes in humans is associated with our work on introspective learning in at least four specific ways. 
<P>First, and foremost, is the emphasis on cognitive self-monitoring.  This behavior is the human ability to read one's own mental states during cognitive processing (Flavell &amp; Wellman, 1977; Nelson &amp; Narens, 1990/1992; Wellman, 1983, 1985).  Thus, there is a moment-by-moment insight into the content of one's mind resulting in an internal feedback for the cognition being performed and a judgement of progress (or lack thereof).  Garner (1987) has argued that metacognition and comprehension monitoring are important factors in the understanding of written text.  Reading comprehension is therefore considered to be chiefly an interaction between a reader's expectations and the textual information.<A HREF="related-res2-chapt.html#FN12">(12)</A> Psychological studies have also confirmed a positive correlation between metamemory and memory performance in cognitive monitoring situations (Schneider, 1985; Wellman, 1983).  This evidence, along with results from the studies above linking problem-solving performance with metacognitive abilities, directly supports the conviction that there must be a second-order introspective process that reflects to some degree on the performance element in an intelligent system, especially a learning system involved in understanding tasks such as story understanding. 

<P>Second, our IML theory places a heavy emphasis on explicit representation.  Trains of thought, as well as the products of thought, are represented as metaknowledge structures, and computation is not simply the calculated results from implicit side-effects of processing.  This emphasis is echoed in Chi's (1987) argument, that to understand knowledge organization and to examine research issues there must be some representational framework.  Although diverging from the framework suggested by Chi, IML theory provides a robust form with which to represent knowledge about knowledge and knowledge about process.  For example, <A HREF="repr-chapt.html#REF78278">Section 4.3</A> illustrated that Meta-XPs can represent the difference between remembering and forgetting (see also Cox, 1994b; Cox &amp; Ram, 1992a), and <A HREF="meta-aqua-chapt.html#REF83295">Section 8.5.4</A> showed that the Meta-AQUA system can use such representations to reorganize memory indexes when forgetting.  In general, forgetting is a neglected issue in AI and computational learning research, yet forgetting is a significant issue in the metamemory literature (Spear, 1978; Wellman &amp; Johnson, 1979).  The meta-explanations in our approach are similar to self-explanations (Chi &amp; VanLehn, 1991; Pirolli &amp; Bielaczyc, 1989; Pirolli &amp; Recker, 1994; VanLehn, Jones &amp; Chi, 1992).  This research shows that formulation of self-explanations while understanding input examples significantly correlates with subjects' ability to learn from the examples.  One difference between the two approaches, however, is that self-explanations are self-generated explanations about the world, whereas meta-explanations are explanations about the self.  Despite the differences, experimental results in the psychological literature support the claim that representational structure is important in learning.  
<P>Third, because the approach taken by the introspective learning paradigm clearly addresses the issues of memory organization, it can assign blame to errors that occur from mis-indexed knowledge structures and poorly organized memory.  As <A HREF="symptoms-chapt.html#REF16647">Section 3.3</A> argues, the memory organization of suspended goals, background knowledge, and reasoning strategies are as important in determining the cause of a reasoning failure as are the goals, propositions and strategies themselves.  Thus, memory retrieval and encoding issues are relevant in deciding what to learn and which learning strategy is appropriate.  This claim is supported by the metamemory community's focus on organizational features of memory and their relation to the human ability to know what one knows, even in the face of an unsuccessful memory retrieval.

<P>Finally, both metacognition theory and IML theory address the issue concerning a person's ability to assess the veracity of their own responses.  In addition, because a person has a FOK, even when recall is blocked, the agent can make efficient use of search.  Search and elaboration is pursued when an item is on the "tip of the tongue'' and abandoned when an item is judged unfamiliar.  This search heuristic provides efficient control of memory and avoids the combinatorial explosion of inferences (Lachman, Lachman &amp; Thronesbery, 1979; Miner &amp; Reder, 1994).  Although people sometimes make spurious and biased inferences when assessing their own memories and reasoning, these inferences nonetheless affect people's decisions and thus are important components when modeling human decision-making.  For example, current case-based reasoners retrieve the best case and adapt it to the current problem.  It is only after the reasoner generates a complete solution and judges it to be incorrect that the system will attempt to retrieve another case for adaptation.  Adding a metacognitive component would allow the case-based reasoner to dynamically judge the progress toward the goal during initial problem-solving (using metacognitive monitoring) and estimate the likelihood of finding another case in memory that applies to the problem (using FOK judgements).  Therefore, the reasoner could prematurely decide to "give up" on the initial case and search for a better one by judging the trade-offs involved.  
<P>One of the major differences between the manner in which humans learn and the manner in which machines do is that humans perform dynamic metacognitive monitoring or self-evaluation.  Humans often know when they are making progress in problem solving, even if they are far from a solution, and they know when they have sufficiently learned something with respect to some goal (Weinert, 1987).  They know how to allocate mental resources and, for example, can judge when learning is over.  Many reviews (e.g., Chi, 1987; Davidson et al., 1994; Miner &amp; Reder, 1994; Nelson &amp; Dunlosky, 1991; Schneider, 1985; Wellman, 1983) cite evidence for such claims.  Research in IML theory is a step in the direction of fully incorporating this metacognitive monitoring capability into artificially intelligent systems.  
<P>It should be noted that the learning strategies represented in Meta-AQUA, are at a finer level of granularity than those examined by much of psychology.  For example, it would be misleading to assert that the types of learning strategies studied by the metacognition community are similar to index learning, explanation-based generalization, and other learning strategies used in Meta-AQUA.  Instead, metacognition research focusses on a person's choice of strategic behaviors at the level of cue elaboration, category grouping, and target rehearsal (in memory tasks); re-reading of text, question generation, and keyword search (in text interpretation tasks); or solution checking, saving intermediate results in an external representation, and comprehension monitoring (in problem-solving tasks).  However, many of the results from research on metacognition do support the overall approach we have taken, that of using introspection to support the selection of appropriate strategies in different situations. 

<P>Not only is there a relation from psychology bearing on IML theory, but the reverse argument can be made as well.  Much of the metaknowledge research in artificial intelligence has focused on knowledge about knowledge and beliefs, or knowledge about the facts that one does or does not know.  Much of the metacognition research in psychology has also focussed on similar issues, focussing on cognitive processes, strategies and knowledge having the self as referent.  Of particular interest is the psychological research on metamemory, which, in addition to knowledge about knowledge, includes knowledge about memory in general and about the peculiarities of one's own memory abilities.  The empirical results obtained from the Meta-AQUA system support the claim that metaknowledge should also include knowledge about reasoning and learning strategies.  Experimental results in the metacognition literature suggests that introspective reasoning can facilitate reasoning and learning (e.g., the studies mentioned earlier: Davidson et al., 1994; Delclos &amp; Harrington, 1991; Nelson &amp; Dunlosky, 1991; and Swanson, 1990).  Our research extends these results by specifying computational mechanisms for metacognitive processing, focussing in particular on the selection and use of learning strategies. 
<H3><A NAME="REF93044"> 11.3   Summary and Discussion </A></H3>
<P>This chapter examined some of the research related to IML theory (but not discussed in previous chapters), both from the artificial intelligence perspective and from the cognitive psychology point of view.  We described the genesis of interest in computational theories of introspection during the formative years of AI. The logic community has a large part to play in this early research because they established a formalism (and a legitimacy) for the representation of mental states and belief, including beliefs about a system's own beliefs.  We also examined the research of the expert system community and others that also claim to be developing introspective systems, but take a different approach.  Finally we looked at systems that combine introspective theories with theories of learning.  Subsequently, this chapter examined psychological research into metacognition, problems solving, metamemory, and the interactions between each.  Both the material on AI theories and that dealing with psychological theories evaluated the relationship between the related research and IML theory and how such research from both fields support the claims presented in this thesis. 
<P>Although this chapter represents a relatively broad and cursory examination of the literature and issues, it nonetheless supports the need for further research into the relationship between metacognitive activities, intelligent performance, and learning, especially since there is a natural affinity between high-level cognition and high-level performance in humans.  The wealth of ideas in both fields that relate to the issues raised here also argue for a stronger bond between those who build qualitative and mathematical theories of human behavior and those who develop computational models.  Yet, before continuing beyond the modest start contained in this thesis, the psychological and AI communities can benefit from better methodological and theoretical foundations.  Often, authors use different terms for the same concept (e.g., introspection and reflection),<A HREF="related-res2-chapt.html#FN13">(13)</A> and sometimes the same terms are used in different ways (e.g., metacognition is a multiple overloaded term).  Indeed, Brown (1987) has described research into metacognition as a "many-headed monster of obscure parentage." The description applies equally as well to the many AI approaches that deal with introspection, learning, and the relation between the two. 

<P>We have attempted to outline and organize some of the bewildering research as it exists in relation to IML theory and the Meta-AQUA implementation.  But until a larger foundation is developed that integrates and supports the many technical approaches and cognitive science perspectives, there may be only limited progress in understanding the computational role of both metacognition in human learning and introspection in machine learning.  After the next chapter summarizes the cornerstones IML theory provides, we speculate in an extended epilogue as to some of the forms such a foundation may assume.  


<HR><H3>Footnotes</H3>
<DL COMPACT>
<DT><A NAME=FN1>(1)</A><DD>Cited in Lyons (1986, p. 1). 
<DT><A NAME=FN2>(2)</A><DD>Minsky notes that he had been considering the ideas in this paper since 1954.  It first appeared as Minsky (1965), although the concluding two pages of Minsky (1961/1963) address exactly the same issue.  A significant portion of McCarthy's ideas was first published as McCarthy (1959). 
<DT><A NAME=FN3>(3)</A><DD>Johnson-Laird (1988, p. 361) explicitly takes issue with the suggestion that Minsky's concept of a self-model was in such a form that it could correspond to a human's capacity for self-reflection.  He claims that Minsky's formulation is equivalent to a Turing machine with an interpreter that consults a complete description of itself (presumably without being able to understand itself), whereas humans consult an imperfect and incomplete mental model that is somehow qualitatively different.  However, this argument appears to be extremely weak because the two positions are so similar and closely related.
<DT><A NAME=FN4>(4)</A><DD>McCarthy (1979; 1995) also outlines a number of additional issues concerning the mental domain that have received lesser attention by the logic community.  He raises the issue of consciousness, language, intentions, free will, understanding and creativity, all of which have come to represent provocative focal aspects of intelligent reasoning. 
<DT><A NAME=FN5>(5)</A><DD>A procedural difference exists between reasoning about a solution or a problem and the metareasoning directed at the reasoning that produces such solutions or engages such problems.  For instance, Carbonell (1986) notes that in order to transfer knowledge from programming a quicksort problem on a computer in Pascal to solving the same problem in LISP, a student cannot analogically map the Pascal solution to LISP code.  The languages are too dissimilar in data structures and process control.  Instead the reasoner must reason about how the original solution was derived and what decisions were made while solving the first problem, analogically mapping the derivation to LISP.  Reasoning is at the algorithm level, rather than the code level. 
<DT><A NAME=FN6>(6)</A><DD>In the terms of Newell (1982), the reasoning should be at the symbol level rather than at the register-transfer level of intelligent systems. 
<DT><A NAME=FN7>(7)</A><DD>This contention concerning planning is also shared by Fox &amp; Leake (1995a). 
<DT><A NAME=FN8>(8)</A><DD>Interestingly, Collins et al. (1993) argue from both a design stance and an intentional stance.
<DT><A NAME=FN9>(9)</A><DD>Brown (1987) notes that the relationship between text comprehension and metacognitive activities has been studied since the turn of the century, but under the guise of other technical terms.
<DT><A NAME=FN10>(10)</A><DD>Pollock (1989b) distinguishes between knowledge about the facts that one knows and knowledge about one's motivations, beliefs and processes.  Introspective multistrategy learning is based on both kinds of metaknowledge; we have argued that introspective access to explicit representations of knowledge and of reasoning processes is essential in making decisions about what and how to learn. 
<DT><A NAME=FN11>(11)</A><DD>I have used some license in interpreting Lovelace's subcategories to assure consistency with Kausler.  Lovelace actually places postdictions in the memory-monitoring subcategory.  He considers the pre-performance estimates category to refer to particular tasks, whereas the category that Kausler calls on-line memory self-evaluation Lovelace calls consequences of variation in task or processing and restricts it to metacognitions for how memory works in general.
<DT><A NAME=FN12>(12)</A><DD>A special relation exists between metacognition, question asking and text understanding (see Gavelek &amp; Raphael, 1985; Pressley &amp; Forrest-Pressley, 1985).  In effect, human learners use question-asking and question-answering strategies to provide an index into their level of comprehension of a given piece of text.  This metacognitive feedback helps readers find areas where their understanding of the story is deficient, and thus where greater processing is necessary.  Such a perspective supports our ancillary claim that question generation is a key activity in text comprehension and also that meta-level processing is important in such a learning context.  As a final tangent, not only is metacognition important in language understanding, it is also important in language generation (i.e., in metalinguistic development; see Gombert, 1992). 
<DT><A NAME=FN13>(13)</A><DD>But although we have used the terms as synonyms until now, Section 13.2 will make a small distinction between introspection and reflection (see Figure 102). 
</DL>
<P><A HREF="git-cc-96-06.book.html"><IMG SRC="fm2html-toc.gif">Table of Contents</A>
<A HREF="conclude-chapt.html"><IMG SRC="fm2html-next.gif">Next Chapter</A>

<HR>

<A HREF="http://www.cc.gatech.edu/aimosaic/students/Ai-students/cox/cox.html"><IMG
ALIGN=MIDDLE
SRC="http://www.cc.gatech.edu/aimosaic/students/Ai-students/cox/Www/Images/home2.gif"></A>

<A HREF="http://www.cc.gatech.edu/cogsci">
<IMG ALIGN=MIDDLE
SRC="http://www.cc.gatech.edu/aimosaic/students/Ai-students/cox/Www/Images/cogsci-granite3.gif"></A>