<P><A HREF="git-cc-96-06.book.html"><IMG SRC="fm2html-toc.gif">Table of Contents</A>
<A HREF="abbreviations.html"><IMG SRC="fm2html-previous.gif">Previous Chapter</A>
<!-- This file was created with the fm2html filter.
The filter is copyright Norwegian Telecom Research and
was programmed by Jon Stephenson von Tetzchner. -->

<TITLE>IML - Summary</TITLE>

<H2><A NAME="REF23634"> SUMMARY</A></H2>
<P><A NAME="REF55078">The thesis put forth by this dissertation is that introspective analyses facilitate the construction of learning strategies.  Furthermore, learning is much like nonlinear planning and problem solving.  Like problem solving, it can be specified by a set of explicit learning goals (i.e., desired changes to the reasoner's knowledge); these goals can be achieved by constructing a plan from a set of operators (the learning algorithms) that execute in a knowledge space.  However, in order to specify learning goals and to avoid negative interactions between operators, a reasoner requires a model of its reasoning processes and knowledge.  With such a model, the reasoner can declaratively represent the events and causal relations of its mental world in the same manner that it represents events and relations in the physical world.  This representation enables introspective self-examination, which contributes to learning by providing a basis for identifying what needs to be learned when reasoning fails.  A multistrategy system possessing several learning algorithms can decide what to learn, and which algorithm(s) to apply, by analyzing the model of its reasoning.  This introspective analysis therefore allows the learner to understand its reasoning failures, to determine the causes of the failures, to identify needed knowledge repairs to avoid such failures in the future, and to build a learning strategy (plan).  Thus, the research goal is to develop both a content theory and a process theory of introspective multistrategy learning and to establish the conditions under which such an approach is fruitful.</A>
<P>Empirical experiments provide results that support the claims herein.  The theory was implemented in a computational model called Meta-AQUA that attempts to understand simple stories.  The system uses case-based reasoning to explain reasoning failures and to generate sets of learning goals, and it uses a standard non-linear planner to achieve these goals.  Evaluating Meta-AQUA with and without learning goals generated results indicating that computational introspection facilitates the learning process.  In particular, the results lead to the conclusion that the stage that posts learning goals is a necessary stage if negative interactions between learning methods are to be avoided and if learning is to remain effective.  <A HREF="abstract.html#REF55078"></A>


<P><A HREF="git-cc-96-06.book.html"><IMG SRC="fm2html-toc.gif">Table of Contents</A>
<A HREF="intro-chapt.html"><IMG SRC="fm2html-next.gif">Next Chapter</A>

<HR>

<A HREF="http://www.cc.gatech.edu/aimosaic/students/Ai-students/cox/cox.html"><IMG
ALIGN=MIDDLE
SRC="http://www.cc.gatech.edu/aimosaic/students/Ai-students/cox/Www/Images/home2.gif"></A>

<A HREF="http://www.cc.gatech.edu/cogsci">
<IMG ALIGN=MIDDLE
SRC="http://www.cc.gatech.edu/aimosaic/students/Ai-students/cox/Www/Images/cogsci-granite3.gif"></A>